# Supervised-Speech-Recognition-with-Transformers
Practical implementations of transformer models: DistilBERT, GPT, and Whisper for text, generation, and speech tasks.

# Transformer Projects

This repository explores the evolution of transformer models and presents three practical implementations that demonstrate their versatility and power across different modalities:

1. **DistilBERT for Sentiment Classification**  
   Fine-tuned on the IMDB movie review dataset, highlighting the effectiveness of pretrained encoder-based transformers for text understanding.

2. **Miniature GPT from Scratch**  
   In-depth exploration of decoder-only transformer architectures, self-attention, and autoregressive text generation.

3. **Whisper for Twi Speech Recognition**  
   Fine-tuned with LoRA adapters, showcasing transformer potential in low-resource language scenarios.

Together, these projects illustrate both foundational principles and practical performance of transformers in classification, generation, and speech-to-text tasks.

